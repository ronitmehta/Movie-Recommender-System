{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yhwnMPyq5xC_"
      },
      "source": [
        "# Movielens Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5sqTx-H2efY",
        "outputId": "75536c60-437d-491a-cede-dbec68072369"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!unzip \"ml-1m.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dlwMJG9r19L3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "# Load user data\n",
        "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, engine='python',encoding='ISO-8859-1')\n",
        "users.columns = ['user_id', 'gender', 'age', 'occupation', 'zip_code']\n",
        "\n",
        "# Load movie data\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, engine='python',encoding='ISO-8859-1')\n",
        "movies.columns = ['movie_id', 'title', 'genres']\n",
        "\n",
        "# Create mapping between original movie IDs and contiguous indices\n",
        "movie_to_index = {}\n",
        "for i, movie_id in enumerate(movies['movie_id'].unique()):\n",
        "    movie_to_index[movie_id] = i\n",
        "\n",
        "# Load ratings data\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, engine='python',encoding='ISO-8859-1')\n",
        "ratings.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "\n",
        "# Convert movie and user IDs to contiguous indices\n",
        "ratings['user_id'] = ratings['user_id'] - 1\n",
        "ratings['movie_id'] = ratings['movie_id'].apply(lambda x: movie_to_index[x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ln3-xjEP2BJr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create sparse adjacency matrix for input into KGCN (assuming movies are connected based on genre)\n",
        "movie_genre = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, engine='python',encoding='ISO-8859-1')\n",
        "movie_genre.columns = ['movie_id', 'title', 'genres']\n",
        "genres = set()\n",
        "for g in movie_genre['genres']:\n",
        "    genres.update(g.split('|'))\n",
        "genre_dict = {g: i for i, g in enumerate(genres)}\n",
        "movie_genre_vec = []\n",
        "for g in movie_genre['genres']:\n",
        "    vec = np.zeros(len(genres))\n",
        "    for gg in g.split('|'):\n",
        "        vec[genre_dict[gg]] = 1\n",
        "    movie_genre_vec.append(vec)\n",
        "movie_genre_mat = np.array(movie_genre_vec)\n",
        "\n",
        "\n",
        "# Create empty adjacency matrix\n",
        "num_users = ratings['user_id'].nunique()\n",
        "num_movies = len(movie_to_index)\n",
        "adj_matrix = np.zeros((num_users, num_movies))\n",
        "\n",
        "# Fill in adjacency matrix with ratings\n",
        "for _, row in ratings.iterrows():\n",
        "    user_id = row['user_id']\n",
        "    movie_id = row['movie_id']\n",
        "    rating = row['rating']\n",
        "    adj_matrix[user_id, movie_id] = rating\n",
        "\n",
        "# Convert adjacency matrix to sparse format\n",
        "adj_matrix = coo_matrix(adj_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u3BpdwXMF7UY"
      },
      "outputs": [],
      "source": [
        "ratings_subset = ratings[['user_id', 'movie_id', 'rating']]\n",
        "genre_cols = [genre for genre, index in sorted(genre_dict.items(), key=lambda x: x[0])]\n",
        "\n",
        "# Merge with movie_genre_mat matrix\n",
        "merged_data = pd.merge(ratings_subset, pd.DataFrame(movie_genre_mat, columns=genre_cols), left_on='movie_id', right_index=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SRgunNrqEPpl"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and test sets\n",
        "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "num_users = ratings['user_id'].max()+1\n",
        "num_movies = ratings['movie_id'].max() +1\n",
        "num_genres = len(genre_dict)\n",
        "batch_size = num_movies\n",
        "\n",
        "# Extract inputs and targets for training set\n",
        "train_users = np.array(train_data['user_id'])\n",
        "train_movies = np.array(train_data['movie_id'])\n",
        "train_movie_genre = np.array(train_data[genre_cols])\n",
        "train_ratings = np.array(train_data['rating'])\n",
        "consistent_length = (train_users.shape[0] // batch_size) * batch_size\n",
        "train_users = train_users[:consistent_length]\n",
        "train_movies = train_movies[:consistent_length]\n",
        "train_movie_genre = train_movie_genre[:consistent_length]\n",
        "train_ratings = train_ratings[:consistent_length]\n",
        "\n",
        "\n",
        "# Extract inputs and targets for validation set\n",
        "val_users = np.array(val_data['user_id'])\n",
        "val_movies = np.array(val_data['movie_id'])\n",
        "val_movie_genre = np.array(val_data[genre_cols])\n",
        "val_ratings = np.array(val_data['rating'])\n",
        "consistent_length = (val_users.shape[0] // batch_size) * batch_size\n",
        "val_users = val_users[:consistent_length]\n",
        "val_movies = val_movies[:consistent_length]\n",
        "val_movie_genre = val_movie_genre[:consistent_length]\n",
        "val_ratings = val_ratings[:consistent_length]\n",
        "\n",
        "# Extract inputs and targets for test set\n",
        "test_users = np.array(test_data['user_id'])\n",
        "test_movies = np.array(test_data['movie_id'])\n",
        "test_movie_genre = np.array(test_data[genre_cols])\n",
        "test_ratings = np.array(test_data['rating'])\n",
        "consistent_length = (test_users.shape[0] // batch_size) * batch_size\n",
        "test_users = test_users[:consistent_length]\n",
        "test_movies = test_movies[:consistent_length]\n",
        "test_movie_genre = test_movie_genre[:consistent_length]\n",
        "test_ratings = test_ratings[:consistent_length]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KGCN implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k0q6LWDC4TJd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense, Embedding, Concatenate, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "\n",
        "# Define hyperparameters\n",
        "num_users = ratings['user_id'].max()+1\n",
        "num_movies = ratings['movie_id'].max() +1\n",
        "\n",
        "num_genres = len(genre_dict)\n",
        "\n",
        "embedding_size = 32\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "batch_size = num_movies\n",
        "reg_lambda = 0.01\n",
        "\n",
        "# Define KGCN model architecture\n",
        "user_input = Input(shape=(1,), name='user_input_kgcn')\n",
        "movie_input = Input(shape=(1,), name='movie_input_kgcn')\n",
        "\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size,  name='user_embedding')(user_input)\n",
        "movie_embedding = Embedding(input_dim=num_movies, output_dim=embedding_size, name='movie_embedding')(movie_input)\n",
        "    \n",
        "user_embedding = Dropout(dropout_rate)(user_embedding)\n",
        "movie_embedding = Dropout(dropout_rate)(movie_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qPb3tA1d4hKJ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Lambda\n",
        "import sys\n",
        "\n",
        "\n",
        "# Concatenate user and movie embeddings\n",
        "\n",
        "genre_input = Input(shape=(num_genres,), name='genre_input')\n",
        "# Define genre embedding and GCN layers\n",
        "genre_embedding = Dense(embedding_size, activation='relu', kernel_regularizer=l2(reg_lambda), name='genre_embedding')(genre_input)\n",
        "# genre_embedding_reshaped = tf.reshape(genre_embedding, shape=(-1, embedding_size)) \n",
        "# genre_embedding_reshaped = Reshape(target_shape=(1, embedding_size))(genre_embedding)\n",
        "# genre_embedding_tiled = tf.tile(genre_embedding_reshaped, [1, num_movies, 1])\n",
        "\n",
        "# print_layer = Lambda(lambda x: tf.print(x, [x], message='genre_embedding_reshaped = '))\n",
        "\n",
        "gcn_1 = tf.linalg.matmul(adj_matrix.toarray(), tf.cast(genre_embedding, tf.float64) , name='gcn_1')\n",
        "# gcn_1=tf.squeeze(gcn_1, axis=0)\n",
        "gcn_2 = tf.linalg.matmul(adj_matrix.toarray().T, gcn_1, name='gcn_2')\n",
        "gcn_2_reshaped = tf.expand_dims(gcn_2, axis=1)\n",
        "\n",
        "user_movie_concat = Concatenate()([user_embedding, movie_embedding])\n",
        "\n",
        "\n",
        "# Concatenate genre embeddings with user-movie embeddings\n",
        "user_movie_genre_concat = Concatenate(axis=2)([user_movie_concat, gcn_2_reshaped])\n",
        "\n",
        "# Define final dense layers and output\n",
        "dense_1 = Dense(64, activation='relu', kernel_regularizer=l2(reg_lambda), name='dense_1')(user_movie_genre_concat)\n",
        "dense_2 = Dense(32, activation='relu', kernel_regularizer=l2(reg_lambda), name='dense_2')(dense_1)\n",
        "output = Dense(1, activation='linear', name='output')(dense_2)\n",
        "\n",
        "kgcn_model = Model(inputs=[user_input, movie_input, genre_input], outputs=output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xVXwIReI4myJ"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "rmse = RootMeanSquaredError()\n",
        "kgcn_model.compile(loss='mse', optimizer=optimizer, metrics=[rmse])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oGhRJh7c96sm"
      },
      "outputs": [],
      "source": [
        "# # Split data into train and test sets\n",
        "# train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "# train_ratings, val_ratings = train_test_split(train_ratings, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "luI5jaiFHL3U",
        "outputId": "630b8df5-291a-4f43-8511-555bf778e3fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>Action</th>\n",
              "      <th>Adventure</th>\n",
              "      <th>Animation</th>\n",
              "      <th>Children's</th>\n",
              "      <th>Comedy</th>\n",
              "      <th>Crime</th>\n",
              "      <th>Documentary</th>\n",
              "      <th>...</th>\n",
              "      <th>Fantasy</th>\n",
              "      <th>Film-Noir</th>\n",
              "      <th>Horror</th>\n",
              "      <th>Musical</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>Romance</th>\n",
              "      <th>Sci-Fi</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1176</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>1</td>\n",
              "      <td>1176</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1339</th>\n",
              "      <td>11</td>\n",
              "      <td>1176</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>14</td>\n",
              "      <td>1176</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1747</th>\n",
              "      <td>16</td>\n",
              "      <td>1176</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984335</th>\n",
              "      <td>5948</td>\n",
              "      <td>2129</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940262</th>\n",
              "      <td>5674</td>\n",
              "      <td>2634</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957826</th>\n",
              "      <td>5779</td>\n",
              "      <td>2776</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970914</th>\n",
              "      <td>5850</td>\n",
              "      <td>3538</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983062</th>\n",
              "      <td>5937</td>\n",
              "      <td>2840</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000209 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        user_id  movie_id  rating  Action  Adventure  Animation  Children's  \\\n",
              "0             0      1176       5     0.0        0.0        0.0         0.0   \n",
              "120           1      1176       5     0.0        0.0        0.0         0.0   \n",
              "1339         11      1176       4     0.0        0.0        0.0         0.0   \n",
              "1518         14      1176       4     0.0        0.0        0.0         0.0   \n",
              "1747         16      1176       5     0.0        0.0        0.0         0.0   \n",
              "...         ...       ...     ...     ...        ...        ...         ...   \n",
              "984335     5948      2129       5     0.0        0.0        0.0         0.0   \n",
              "940262     5674      2634       3     0.0        0.0        0.0         0.0   \n",
              "957826     5779      2776       1     0.0        0.0        0.0         0.0   \n",
              "970914     5850      3538       5     0.0        0.0        0.0         0.0   \n",
              "983062     5937      2840       4     0.0        0.0        0.0         0.0   \n",
              "\n",
              "        Comedy  Crime  Documentary  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
              "0          0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "120        0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "1339       0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "1518       0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "1747       0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "...        ...    ...          ...  ...      ...        ...     ...      ...   \n",
              "984335     0.0    1.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "940262     0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "957826     0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "970914     0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "983062     0.0    1.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
              "\n",
              "        Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
              "0           0.0      0.0     1.0       0.0  0.0      0.0  \n",
              "120         0.0      0.0     1.0       0.0  0.0      0.0  \n",
              "1339        0.0      0.0     1.0       0.0  0.0      0.0  \n",
              "1518        0.0      0.0     1.0       0.0  0.0      0.0  \n",
              "1747        0.0      0.0     1.0       0.0  0.0      0.0  \n",
              "...         ...      ...     ...       ...  ...      ...  \n",
              "984335      0.0      0.0     0.0       0.0  0.0      0.0  \n",
              "940262      0.0      0.0     1.0       0.0  0.0      0.0  \n",
              "957826      0.0      0.0     1.0       0.0  0.0      0.0  \n",
              "970914      0.0      0.0     1.0       0.0  1.0      0.0  \n",
              "983062      0.0      0.0     0.0       0.0  0.0      0.0  \n",
              "\n",
              "[1000209 rows x 21 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o0Uqoyu28bLN",
        "outputId": "9113869c-81c0-4cad-c94d-d61de5949a76"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "history = kgcn_model.fit([train_users, train_movies, train_movie_genre], train_ratings, validation_data=([val_users, val_movies, val_movie_genre], val_ratings),batch_size=batch_size, epochs=2, verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 10s 203ms/step - loss: 62069240.0000 - root_mean_squared_error: 7878.4023\n",
            "Test Loss: 62069240.0000, Test RMSE: 7878.4023\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate model on test set\n",
        "test_loss, test_rmse = kgcn_model.evaluate([test_users, test_movies, test_movie_genre], test_ratings, batch_size=batch_size,verbose =1)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test RMSE: {test_rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 9s 165ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on test set\n",
        "test_preds = kgcn_model.predict([test_users, test_movies, test_movie_genre], batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE: 7878.4019\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "test_rmse = np.sqrt(mean_squared_error(test_ratings, np.squeeze(test_preds)))\n",
        "print(f'Test RMSE: {test_rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NeuMF implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2488/2488 [==============================] - 10s 3ms/step - loss: 1604.0406 - root_mean_squared_error: 40.0405 - val_loss: 3.0292 - val_root_mean_squared_error: 1.4869\n",
            "Epoch 2/20\n",
            "2488/2488 [==============================] - 9s 4ms/step - loss: 2.8780 - root_mean_squared_error: 1.4352 - val_loss: 2.1930 - val_root_mean_squared_error: 1.1757\n",
            "Epoch 3/20\n",
            "2488/2488 [==============================] - 10s 4ms/step - loss: 2.2620 - root_mean_squared_error: 1.2133 - val_loss: 2.1060 - val_root_mean_squared_error: 1.1608\n",
            "Epoch 4/20\n",
            "2488/2488 [==============================] - 9s 3ms/step - loss: 2.2547 - root_mean_squared_error: 1.2418 - val_loss: 2.6828 - val_root_mean_squared_error: 1.4224\n",
            "Epoch 5/20\n",
            "2488/2488 [==============================] - 9s 4ms/step - loss: 2.1439 - root_mean_squared_error: 1.2446 - val_loss: 1.7825 - val_root_mean_squared_error: 1.1215\n",
            "Epoch 6/20\n",
            "2488/2488 [==============================] - 8s 3ms/step - loss: 1.9721 - root_mean_squared_error: 1.2352 - val_loss: 1.9193 - val_root_mean_squared_error: 1.2456\n",
            "Epoch 7/20\n",
            "2488/2488 [==============================] - 8s 3ms/step - loss: 1.8248 - root_mean_squared_error: 1.2373 - val_loss: 1.5149 - val_root_mean_squared_error: 1.1365\n",
            "Epoch 8/20\n",
            "2488/2488 [==============================] - 7s 3ms/step - loss: 1.6869 - root_mean_squared_error: 1.2343 - val_loss: 1.9124 - val_root_mean_squared_error: 1.3422\n",
            "Epoch 9/20\n",
            "2488/2488 [==============================] - 7s 3ms/step - loss: 1.5821 - root_mean_squared_error: 1.2275 - val_loss: 1.8163 - val_root_mean_squared_error: 1.3296\n",
            "Epoch 10/20\n",
            "2488/2488 [==============================] - 7s 3ms/step - loss: 1.5565 - root_mean_squared_error: 1.2335 - val_loss: 1.3305 - val_root_mean_squared_error: 1.1420\n",
            "Epoch 11/20\n",
            "2488/2488 [==============================] - 8s 3ms/step - loss: 1.5209 - root_mean_squared_error: 1.2237 - val_loss: 1.7513 - val_root_mean_squared_error: 1.3151\n",
            "Epoch 12/20\n",
            "2488/2488 [==============================] - 7s 3ms/step - loss: 1.5209 - root_mean_squared_error: 1.2246 - val_loss: 1.3549 - val_root_mean_squared_error: 1.1550\n",
            "Epoch 13/20\n",
            "2488/2488 [==============================] - 8s 3ms/step - loss: 1.5217 - root_mean_squared_error: 1.2252 - val_loss: 1.2995 - val_root_mean_squared_error: 1.1309\n",
            "Epoch 14/20\n",
            "2488/2488 [==============================] - 8s 3ms/step - loss: 1.5222 - root_mean_squared_error: 1.2255 - val_loss: 1.8528 - val_root_mean_squared_error: 1.3538\n",
            "Epoch 15/20\n",
            "2488/2488 [==============================] - 7s 3ms/step - loss: 1.4804 - root_mean_squared_error: 1.2085 - val_loss: 2.0538 - val_root_mean_squared_error: 1.4262\n",
            "Epoch 16/20\n",
            "2488/2488 [==============================] - 10s 4ms/step - loss: 1.5153 - root_mean_squared_error: 1.2229 - val_loss: 1.3467 - val_root_mean_squared_error: 1.1520\n",
            "Epoch 17/20\n",
            "2488/2488 [==============================] - 11s 4ms/step - loss: 1.5000 - root_mean_squared_error: 1.2167 - val_loss: 1.6073 - val_root_mean_squared_error: 1.2601\n",
            "Epoch 18/20\n",
            "2488/2488 [==============================] - 9s 3ms/step - loss: 1.5184 - root_mean_squared_error: 1.2243 - val_loss: 1.5084 - val_root_mean_squared_error: 1.2203\n",
            "Epoch 19/20\n",
            "2488/2488 [==============================] - 7s 3ms/step - loss: 1.5089 - root_mean_squared_error: 1.2205 - val_loss: 2.6006 - val_root_mean_squared_error: 1.6067\n",
            "Epoch 20/20\n",
            "2488/2488 [==============================] - 8s 3ms/step - loss: 1.4892 - root_mean_squared_error: 1.2124 - val_loss: 1.2957 - val_root_mean_squared_error: 1.1299\n",
            "6189/6189 [==============================] - 11s 2ms/step - loss: 1.3057 - root_mean_squared_error: 1.1343\n",
            "Test Loss: 1.3057, Test RMSE: 1.1343\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "\n",
        "latent_dim_nn = 8\n",
        "latent_dim_mf = 8\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "batch_size = 256\n",
        "reg_lambda = 0.01\n",
        "\n",
        "# Define NeuMF model architecture\n",
        "user_input = Input(shape=(1,), name='nn_user_input')\n",
        "movie_input = Input(shape=(1,), name='movie_input')\n",
        "\n",
        "# Define MLP embedding layers\n",
        "nn_user_embedding = Dense(latent_dim_nn, activation='relu', kernel_regularizer=l2(reg_lambda), name='nn_user_embedding')(user_input)\n",
        "nn_movie_embedding = Dense(latent_dim_nn, activation='relu', kernel_regularizer=l2(reg_lambda), name='nn_movie_embedding')(movie_input)\n",
        "\n",
        "# Define MLP layers\n",
        "nn_layer_1 = Dense(64, activation='relu', kernel_regularizer=l2(reg_lambda), name='nn_layer_1')(Concatenate()([nn_user_embedding, nn_movie_embedding]))\n",
        "nn_layer_1 = Dropout(dropout_rate)(nn_layer_1)\n",
        "nn_layer_2 = Dense(32, activation='relu', kernel_regularizer=l2(reg_lambda), name='nn_layer_2')(nn_layer_1)\n",
        "nn_layer_2 = Dropout(dropout_rate)(nn_layer_2)\n",
        "nn_layer_3 = Dense(16, activation='relu', kernel_regularizer=l2(reg_lambda), name='nn_layer_3')(nn_layer_2)\n",
        "\n",
        "# Define MF embedding layers\n",
        "mf_user_embedding = Dense(latent_dim_mf, activation='relu', kernel_regularizer=l2(reg_lambda), name='mf_user_embedding')(user_input)\n",
        "mf_movie_embedding = Dense(latent_dim_mf, activation='relu', kernel_regularizer=l2(reg_lambda), name='mf_movie_embedding')(movie_input)\n",
        "\n",
        "# Concatenate nn and MF layers\n",
        "nnmf_layer = Concatenate()([mf_user_embedding, mf_movie_embedding, nn_layer_3])\n",
        "\n",
        "# Define output\n",
        "output = Dense(1, activation='linear', name='outputnnmf')(nnmf_layer)\n",
        "\n",
        "NN_model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "rmse = RootMeanSquaredError()\n",
        "NN_model.compile(loss='mse', optimizer=optimizer, metrics=[rmse])\n",
        "\n",
        "# Train model\n",
        "history = NN_model.fit([train_users, train_movies], train_ratings,\n",
        "                    validation_data=([val_users, val_movies], val_ratings),\n",
        "                    batch_size=batch_size, epochs=num_epochs, verbose=1)\n",
        "\n",
        "# Evaluate model on test set\n",
        "test_loss, test_rmse = NN_model.evaluate([test_users, test_movies], test_ratings)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test RMSE: {test_rmse:.4f}')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CCCFNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout, BatchNormalization, Flatten, Softmax, Dot\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define input shapes\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "genre_input = Input(shape=(num_genres,))\n",
        "\n",
        "\n",
        "# Define user and movie embeddings\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, name='user_embedding_cccfnet')(user_input)\n",
        "movie_embedding = Embedding(input_dim=num_movies, output_dim=embedding_size, name='movie_embedding_cccfnet')(movie_input)\n",
        "\n",
        "# Define MLP model for user and movie embeddings\n",
        "mlp_layer1 = Concatenate()([Flatten()(user_embedding), Flatten()(movie_embedding)])\n",
        "mlp_layer2 = Dense(64, activation='relu')(mlp_layer1)\n",
        "mlp_layer3 = Dropout(0.2)(mlp_layer2)\n",
        "mlp_layer4 = Dense(32, activation='relu')(mlp_layer3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define attention-based model for genre embedding\n",
        "genre_layer1 = Dense(embedding_size, activation='relu')(genre_input)\n",
        "genre_layer2 = BatchNormalization()(genre_layer1)\n",
        "genre_layer3 = Dense(embedding_size, activation='relu')(genre_layer2)\n",
        "genre_layer4 = BatchNormalization()(genre_layer3)\n",
        "genre_layer5 = Dense(embedding_size, activation='relu')(genre_layer4)\n",
        "genre_layer5_reshaped = Reshape((1, embedding_size))(genre_layer5)\n",
        "attention_scores = Dot(axes=(2,1))([movie_embedding, genre_layer5])\n",
        "attention_scores = Reshape((1,))(attention_scores)\n",
        "attention_weights = Softmax()(attention_scores)\n",
        "attention_output = Dot(axes=(1,1))([movie_embedding, attention_weights])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Combine the outputs from the MLP and attention-based models\n",
        "final_layer1 = Concatenate()([mlp_layer4, attention_output])\n",
        "final_layer2 = Dense(16, activation='relu')(final_layer1)\n",
        "final_output = Dense(1)(final_layer2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define the model\n",
        "cccfnet_model = Model(inputs=[user_input, movie_input, genre_input], outputs=final_output)\n",
        "\n",
        "# Compile the model\n",
        "cccfnet_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Train the model\n",
        "history = cccfnet_model.fit([train_users, train_movies, train_movie_genre], train_ratings, validation_data=([val_users, val_movies, val_movie_genre], val_ratings), batch_size=batch_size, epochs=10, verbose=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.7830, Validation RMSE: 0.7830\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model on the validation set\n",
        "val_loss, val_rmse = cccfnet_model.evaluate([test_users, test_movies, test_movie_genre], test_ratings, batch_size=batch_size, verbose=0)\n",
        "print(f'Validation Loss: {val_loss:.4f}, Validation RMSE: {val_rmse:.4f}')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combined Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine the outputs from the KGCN, NeuMF, and CCCFNet models\n",
        "kgcn_output = kgcn_model.output\n",
        "nn_output = NN_model.output\n",
        "cccfnet_output = cccfnet_model.output\n",
        "\n",
        "kgcn_output = Flatten()(kgcn_output)\n",
        "\n",
        "combined_output = Concatenate(axis = 1)([kgcn_output, nn_output, cccfnet_output])\n",
        "combined_layer1 = Dense(16, activation='relu')(combined_output)\n",
        "final_output = Dense(1)(combined_layer1)\n",
        "\n",
        "# Define the combined model\n",
        "combined_model = Model(inputs=[kgcn_model.input, NN_model.input, cccfnet_model.input], outputs=final_output)\n",
        "\n",
        "# Compile the combined model\n",
        "combined_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 680, in _run_internal_graph\n        assert x_id in tensor_dict, \"Could not compute output \" + str(x)\n\n    AssertionError: Exception encountered when calling layer 'model_18' (type Functional).\n    \n    Could not compute output KerasTensor(type_spec=TensorSpec(shape=(3883, 1), dtype=tf.float32, name=None), name='dense_56/BiasAdd:0', description=\"created by layer 'dense_56'\")\n    \n    Call arguments received by layer 'model_18' (type Functional):\n      • inputs=('tf.Tensor(shape=(None,), dtype=int64)', 'tf.Tensor(shape=(None,), dtype=int64)', 'tf.Tensor(shape=(None, 18), dtype=float32)')\n      • training=True\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[236], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the combined model on the training set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m combined_model\u001b[39m.\u001b[39;49mfit([ train_users, train_movies, train_movie_genre],train_ratings,validation_data\u001b[39m=\u001b[39;49m([val_users, val_movies, val_movie_genre],val_ratings),batch_size\u001b[39m=\u001b[39;49mbatch_size,epochs\u001b[39m=\u001b[39;49mnum_epochs,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Evaluate the performance of the combined model on the validation set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m results \u001b[39m=\u001b[39m combined_model\u001b[39m.\u001b[39mevaluate([val_users, val_movies, val_movie_genre],val_ratings,verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenqumhf9c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mAssertionError\u001b[0m: in user code:\n\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ABHIJEET\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 680, in _run_internal_graph\n        assert x_id in tensor_dict, \"Could not compute output \" + str(x)\n\n    AssertionError: Exception encountered when calling layer 'model_18' (type Functional).\n    \n    Could not compute output KerasTensor(type_spec=TensorSpec(shape=(3883, 1), dtype=tf.float32, name=None), name='dense_56/BiasAdd:0', description=\"created by layer 'dense_56'\")\n    \n    Call arguments received by layer 'model_18' (type Functional):\n      • inputs=('tf.Tensor(shape=(None,), dtype=int64)', 'tf.Tensor(shape=(None,), dtype=int64)', 'tf.Tensor(shape=(None, 18), dtype=float32)')\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Train the combined model on the training set\n",
        "history = combined_model.fit([ train_users, train_movies, train_movie_genre, train_users, train_movies, train_movie_genre,train_users, train_movies, train_movie_genre],train_ratings,validation_data=([[val_users, val_movies, val_movie_genre],[val_users, val_movies, val_movie_genre],[val_users, val_movies, val_movie_genre]],[val_ratings, val_ratings, val_ratings]),batch_size=batch_size,epochs=num_epochs,verbose=1)\n",
        "\n",
        "# Evaluate the performance of the combined model on the validation set\n",
        "results = combined_model.evaluate([val_users, val_movies, val_movie_genre,val_users, val_movies, val_movie_genre,val_users, val_movies, val_movie_genre],val_ratings,verbose=0)\n",
        "print(f\"Validation loss: {results[0]}, Validation MSE: {results[1]}, Validation MAE: {results[2]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None, 18)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_50 (Dense)               (None, 32)           608         ['input_15[0][0]']               \n",
            "                                                                                                  \n",
            " genre_input (InputLayer)       [(None, 18)]         0           []                               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32)          128         ['dense_50[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " genre_embedding (Dense)        (None, 32)           608         ['genre_input[0][0]']            \n",
            "                                                                                                  \n",
            " nn_user_input (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " movie_input (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_51 (Dense)               (None, 32)           1056        ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " user_input_kgcn (InputLayer)   [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " movie_input_kgcn (InputLayer)  [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.cast_8 (TFOpLambda)         (None, 32)           0           ['genre_embedding[0][0]']        \n",
            "                                                                                                  \n",
            " nn_user_embedding (Dense)      (None, 8)            16          ['nn_user_input[0][0]']          \n",
            "                                                                                                  \n",
            " nn_movie_embedding (Dense)     (None, 8)            16          ['movie_input[0][0]']            \n",
            "                                                                                                  \n",
            " user_embedding_cccfnet (Embedd  (None, 1, 32)       193280      ['input_13[0][0]']               \n",
            " ing)                                                                                             \n",
            "                                                                                                  \n",
            " movie_embedding_cccfnet (Embed  (None, 1, 32)       124256      ['input_14[0][0]']               \n",
            " ding)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 32)          128         ['dense_51[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " user_embedding_kgcn (Embedding  (None, 1, 32)       193280      ['user_input_kgcn[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " movie_embedding (Embedding)    (None, 1, 32)        124256      ['movie_input_kgcn[0][0]']       \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_14 (TFOpLambd  (6040, 32)          0           ['tf.cast_8[0][0]']              \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 16)           0           ['nn_user_embedding[0][0]',      \n",
            "                                                                  'nn_movie_embedding[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_10 (Flatten)           (None, 32)           0           ['user_embedding_cccfnet[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_11 (Flatten)           (None, 32)           0           ['movie_embedding_cccfnet[0][0]']\n",
            "                                                                                                  \n",
            " dense_52 (Dense)               (None, 32)           1056        ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 1, 32)        0           ['user_embedding_kgcn[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 1, 32)        0           ['movie_embedding[0][0]']        \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_15 (TFOpLambd  (3883, 32)          0           ['tf.linalg.matmul_14[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " nn_layer_1 (Dense)             (None, 64)           1088        ['concatenate_31[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 64)           0           ['flatten_10[0][0]',             \n",
            "                                                                  'flatten_11[0][0]']             \n",
            "                                                                                                  \n",
            " dot_13 (Dot)                   (None, 1)            0           ['movie_embedding_cccfnet[0][0]',\n",
            "                                                                  'dense_52[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 1, 64)        0           ['dropout_17[0][0]',             \n",
            "                                                                  'dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " tf.expand_dims_6 (TFOpLambda)  (3883, 1, 32)        0           ['tf.linalg.matmul_15[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 64)           0           ['nn_layer_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_48 (Dense)               (None, 64)           4160        ['concatenate_33[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_17 (Reshape)           (None, 1)            0           ['dot_13[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenate)   (3883, 1, 96)        0           ['concatenate_24[0][0]',         \n",
            "                                                                  'tf.expand_dims_6[0][0]']       \n",
            "                                                                                                  \n",
            " nn_layer_2 (Dense)             (None, 32)           2080        ['dropout_22[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_24 (Dropout)           (None, 64)           0           ['dense_48[0][0]']               \n",
            "                                                                                                  \n",
            " softmax_4 (Softmax)            (None, 1)            0           ['reshape_17[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (3883, 1, 64)        6208        ['concatenate_25[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 32)           0           ['nn_layer_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_49 (Dense)               (None, 32)           2080        ['dropout_24[0][0]']             \n",
            "                                                                                                  \n",
            " dot_14 (Dot)                   (None, 32)           0           ['movie_embedding_cccfnet[0][0]',\n",
            "                                                                  'softmax_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (3883, 1, 32)        2080        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " mf_user_embedding (Dense)      (None, 8)            16          ['nn_user_input[0][0]']          \n",
            "                                                                                                  \n",
            " mf_movie_embedding (Dense)     (None, 8)            16          ['movie_input[0][0]']            \n",
            "                                                                                                  \n",
            " nn_layer_3 (Dense)             (None, 16)           528         ['dropout_23[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 64)           0           ['dense_49[0][0]',               \n",
            "                                                                  'dot_14[0][0]']                 \n",
            "                                                                                                  \n",
            " output (Dense)                 (3883, 1, 1)         33          ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 32)           0           ['mf_user_embedding[0][0]',      \n",
            "                                                                  'mf_movie_embedding[0][0]',     \n",
            "                                                                  'nn_layer_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_53 (Dense)               (None, 16)           1040        ['concatenate_34[0][0]']         \n",
            "                                                                                                  \n",
            " flatten_12 (Flatten)           (3883, 1)            0           ['output[0][0]']                 \n",
            "                                                                                                  \n",
            " outputnnmf (Dense)             (None, 1)            33          ['concatenate_32[0][0]']         \n",
            "                                                                                                  \n",
            " dense_54 (Dense)               (None, 1)            17          ['dense_53[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (3883, 3)            0           ['flatten_12[0][0]',             \n",
            "                                                                  'outputnnmf[0][0]',             \n",
            "                                                                  'dense_54[0][0]']               \n",
            "                                                                                                  \n",
            " dense_55 (Dense)               (3883, 16)           64          ['concatenate_35[0][0]']         \n",
            "                                                                                                  \n",
            " dense_56 (Dense)               (3883, 1)            17          ['dense_55[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 658,148\n",
            "Trainable params: 658,020\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "combined_model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
